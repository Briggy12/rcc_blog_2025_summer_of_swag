---
title: "Police Sentiment Scores | City of Chicago Dataset Project"
author: "Briggy12"
date: "2025.8.7"
categories: [data_science,general]
---

## My Project

Quick Links:

-   data.gov page: <https://catalog.data.gov/dataset/police-sentiment-scores>
    -   This is where I originally retrieved the data set from.
-   Original posting from the Chicago Data Portal: <https://data.cityofchicago.org/Public-Safety/Police-Sentiment-Scores/28me-84fj/about_data>
    -   Here's some more information on the data and explanation of variables.
-   Chicago Police Department's Sentiment Dashboard: <https://www.chicagopolice.org/statistics-data/data-dashboards/sentiment-dashboard/>
    -   Here's CPD's report on the data. On the site, they've also posted some breakdowns and graphic models of their own on the same data.

### Introduction

Over the summer, I attended a Title III/MSIEP grant workshop that focused on data science and analytics using R. As part of the workshop, we were asked to find a data set and ask a overarching question that could be solved through modeling the data, using the skills we learned in R.

### Explanation of Data/Methods

When looking for a data set, I wanted to dive into something more political and within my interests. I found [this data set](https://catalog.data.gov/dataset/police-sentiment-scores) on data.gov (<https://catalog.data.gov/dataset/police-sentiment-scores>) which showed data on the participants' trust of the police, their overall personal measurement of their safety (i.e. "how safe do you feel?"), and how much do you feel the police listen to your area and take that feedback into account.

Participants were asked to rate these factors on a scale from 1-10. Each question also was tied to the demographics of participants, concerning race, age, sex, education level (as in high school diploma or less, some college, and high ed degree), and income.

The survey was broadcasted through advertisements and was self-reporting and optional.

### Research Question

My main question was "which race trusts police/CPD the most?" so much of my models focus on that and related breakdowns of the data, but I wrote code to explore some other statistics as well.

### EDA (Exploratory Data Analysis)

Below, you'll find the code that I ran in R to create models from this data set. I used the package `ggplot2` to create models of the data set.

```{r}
install.packages("ggplot2")
library(ggplot2)

PSS <- read.csv("Police_Sentiment_Scores.csv")

#lets make a general count of what participants we have?


# vv for these down here: change "N/A" to something in AREA and choose a different  color palette
ggplot(data = PSS, aes(x=T_SEX_MALE, color=AREA, fill=AREA)) + geom_bar(position="fill")
ggplot(data = PSS, aes(x=T_SEX_FEMALE, color=AREA, fill=AREA)) + geom_bar(position="fill")

# ehhh this one kinda sucks because they're independant variables
ggplot(data = PSS, aes(x=S_RACE_WHITE, y=AREA, color=AREA, fill=AREA)) + geom_point(size=.5, alpha=.5, position="jitter")


## maybe if I want to make a "map" of where people live, try sorting a count-based graph with each of the race categorizations? Therefore omiting their values and just counting the occurances. Could probably make a new variable using the count() function

#use tidyverse gather()

```

So let's check by area.

In the dataset, there's 9 categorizations of the reported area (each of these are better explained in [CPD's Sentiment Dashboard](https://www.chicagopolice.org/statistics-data/data-dashboards/sentiment-dashboard/)):

1.  **"N/A"**, or no area reported
2.  **"Area 1"**, meaning McKinley Park, Chicago Lawn, Ashburn, Clearing, Woodlawn, South Shore, Oakland, etc.

```{r}
#| fig-height: 6

library(ggridges)

#change label names vv add to density below there
#prettier_labels_PSS <- PSS |>
#  mutate(
#    Student_Athlete_Code_Better = case_when(
#      Student_Athlete_Code == TRUE ~ "Student Athlete", 
#      Student_Athlete_Code == FALSE ~ "Non-Student Athlete"
#    )
#  )

ggplot(
  data = PSS,
  mapping = aes(y = AREA)
) + ggridges::geom_density_ridges(
  mapping = aes(x = S_RACE_WHITE),
  color = "red", fill="red", alpha = 0.3
) + ggridges::geom_density_ridges(
  mapping = aes(x = S_RACE_AFRICAN_AMERICAN),
  color = "blue", fill="blue", alpha = 0.3
) + labs(
    title = "Trust Level for Police",
    subtitle = "Black vs White population",
    x = "Trust Level (1-100)",
    y = "Area",
    )

ggplot(data = PSS, aes(x=S_RACE_WHITE, color=AREA, fill=AREA)) + geom_density(alpha=.75) + facet_wrap(~AREA)
```

```{r}
ggplot(
  data = PSS,
  mapping = aes(y = AREA)
) + ggridges::geom_density_ridges(
  mapping = aes(x = S_RACE_WHITE),
  color = "red", alpha = 0.3
) + ggridges::geom_density_ridges(
  mapping = aes(x = S_RACE_HISPANIC),
  color = "blue", alpha = 0.3
) + ggridges::geom_density_ridges(
  mapping = aes(x = S_RACE_AFRICAN_AMERICAN),
  color = "green", alpha = 0.3
) + facet_wrap(~AREA)
```

### Conclusion

I want to check back with my previous workshops that involved EDA and see what the format was there to make this more professional and mirror the academia process for it. It makes it more accessible and preps me for whatever's to come in the future that does this.
